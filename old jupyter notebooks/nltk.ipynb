{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIN 373 UT Austin :: Jessy Li\n",
    "Some examples and wording taken from: https://www.guru99.com/nltk-tutorial.html\n",
    "\n",
    "# Basic NLTK usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all') # 3.2 gig space!! only run if you have the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "sentence = \"Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.\"\n",
    "print(sentence.split())\n",
    "\n",
    "from nltk import word_tokenize\n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group. Rudolph Agnew, 55 years old and former chairman of Consolidated Gold Fields PLC, was named a director of this British industrial conglomerate.\"\"\"\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paragraph.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "print(sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using word tokenization with sentence tokenization\n",
    "new_data = []\n",
    "for sentence in sent_tokenize(paragraph):\n",
    "    new_data.append(word_tokenize(sentence))\n",
    "print(new_data[0])\n",
    "print(new_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization and Steminning\n",
    "\n",
    "Stemming is a kind of normalization for words. Normalization is a technique where a set of words in a sentence are converted into a sequence to shorten its lookup. The words which have the same meaning but have some variation according to the context or sentence are normalized. https://text-processing.com/demo/stem/\n",
    "\n",
    "There are stemmers for: \n",
    " - Arabic\n",
    " - Danish\n",
    " - Dutch\n",
    " - English\n",
    " - Finnish\n",
    " - French\n",
    " - German\n",
    " - Hungarian\n",
    " - Italian\n",
    " - Norwegian\n",
    " - Porter\n",
    " - Portuguese\n",
    " - Romanian\n",
    " - Russian\n",
    " - Spanish\n",
    " - Swedish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer  = PorterStemmer()\n",
    "text = \"studies studying cries cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print(\"Stemming for {} is {}\".format(w,porter_stemmer.stem(w)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization usually refers to the morphological analysis of words, which aims to remove inflectional endings. It helps in returning the base or dictionary form of a word, which is known as the lemma. The NLTK Lemmatization method is based on WorldNet's built-in morph function. Text preprocessing includes both stemming as well as lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "text = \"studies studying cries cry\"\n",
    "tokenization = nltk.word_tokenize(text)\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    " | Abbreviation | Meaning | \n",
    " | --- | --- | \n",
    " | CC | coordinating conjunction | \n",
    " | CD | cardinal digit | \n",
    " | DT | determiner | \n",
    " | EX | existential there | \n",
    " | FW | foreign word | \n",
    " | IN | preposition/subordinating conjunction | \n",
    " | JJ | adjective (large) | \n",
    " | JJR | adjective, comparative (larger) | \n",
    " | JJS | adjective, superlative (largest) | \n",
    " | LS | list market | \n",
    " | MD | modal (could, will) | \n",
    " | NN | noun, singular (cat, tree) | \n",
    " | NNS | noun plural (desks) | \n",
    " | NNP | proper noun, singular (sarah) | \n",
    " | NNPS | proper noun, plural (indians or americans) | \n",
    " | PDT | predeterminer (all, both, half) | \n",
    " | POS | possessive ending (parent\\ 's) | \n",
    " | PRP | personal pronoun (hers, herself, him,himself) | \n",
    " | PRP$ | possessive pronoun (her, his, mine, my, our ) | \n",
    " | RB | adverb (occasionally, swiftly) | \n",
    " | RBR | adverb, comparative (greater) | \n",
    " | RBS | adverb, superlative (biggest) | \n",
    " | RP | particle (about) | \n",
    " | TO | infinite marker (to) | \n",
    " | UH | interjection (goodbye) | \n",
    " | VB | verb (ask) | \n",
    " | VBG | verb gerund (judging) | \n",
    " | VBD | verb past tense (pleaded) | \n",
    " | VBN | verb past participle (reunified) | \n",
    " | VBP | verb, present tense not 3rd person singular(wrap) | \n",
    " | VBZ | verb, present tense with 3rd person singular (bases) | \n",
    " | WDT | wh-determiner (that, what) | \n",
    " | WP | wh- pronoun (who) | \n",
    " | WRB | wh- adverb (how) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "print(new_data[0])\n",
    "tagged = pos_tag(new_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition using chunking\n",
    "\n",
    "a type of shallow parsing (only two levels) that takes in a POS tagged sentence and predicts the named entities in a text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "from nltk import ne_chunk\n",
    "# sent = ## sentence tokenization\n",
    "\n",
    "sent = \"Mr Vinken is chairman of the Dutch publishing group.\"\n",
    "print(sent)\n",
    "print(sent)\n",
    "tree = ne_chunk(tagged)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"active\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(\"Synonyms for active:\", set(synonyms))\n",
    "print(\"Antonyms for active:\", set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other python processing packages\n",
    "- https://spacy.io/\n",
    "    - English, German, French, Spanish, Portuguese, Italian, Dutch, Greek, Norwegian Bokmal, Lithuanian\n",
    "- https://guides.library.upenn.edu/japanesetext\n",
    "    - Japanese\n",
    "- https://pypi.org/project/polyglot/\n",
    "\t- Tokenization (165 Languages)\n",
    "\t- Language detection (196 Languages)\n",
    "\t- Named Entity Recognition (40 Languages)\n",
    "\t- Part of Speech Tagging (16 Languages)\n",
    "\t- Sentiment Analysis (136 Languages)\n",
    "\t- Word Embeddings (137 Languages)\n",
    "\t- Morphological analysis (135 Languages)\n",
    "\t- Transliteration (69 Languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
